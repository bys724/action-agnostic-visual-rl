# Development Status & Next Steps

**Date**: 2026-02-09
**Last Updated**: After Decoder Design Q&A session

---

## ğŸ“Š Current Implementation Status

### âœ… Completed

**Model Architecture** (`src/models/two_stream.py`):
- âœ… Two-Stream Preprocessing (M: 4ch, P: 5ch)
- âœ… InterleavedTwoStreamViT (CLS Exchange, 3 stages)
- âœ… PixelwiseFusion
- âš ï¸ VideoDecoder (í˜„ì¬: patchesë§Œ ì‚¬ìš©, **ì—…ë°ì´íŠ¸ í•„ìš”**)

**Training**:
- âœ… BridgeDataset implementation
- âœ… EgoDexDataset implementation
- âœ… Multi-gap sampling (1-10 frames)
- âœ… Training pipeline with DataParallel

**Checkpoints**:
- Latest: `data/checkpoints/two_stream/20260202_085022/`
- Progress: 46/350 epochs (13%)
- Dataset: Bridge V2 (1.24M train, 324K eval)
- Best eval loss: 0.0000379

---

## ğŸ¯ Current Task: Decoder Update

### Problem

**Current decoder** (line 578-632):
```python
# Patchesë§Œ ì‚¬ìš©, ì´ì „ ì´ë¯¸ì§€ ì—†ìŒ
def forward(self, patches):
    x = self.input_proj(patches)
    # ... upsampling ...
    return img_pred
```

**Issues**:
1. ëª¨ë“  decoder levelì— P_CLS_finalë§Œ ë°˜ë³µ ì£¼ì…
2. EncoderëŠ” ê° stageë§ˆë‹¤ ì§„í™”í•˜ëŠ” CLS ì‚¬ìš© (ë¶ˆì¼ì¹˜)
3. Skip connection ì—†ìŒ

### Solution: Intermediate CLS + Skip

```python
# Encoder: Save intermediate CLS
P_CLS_stage1 = layer4_output[:, 0]   # Low-level
P_CLS_stage2 = layer8_output[:, 0]   # Mid-level
P_CLS_final  = layer12_output[:, 0]  # High-level

# Decoder: Multi-scale injection
Level 1 (14â†’28):   P_CLS_final    # Abstract
Level 2 (28â†’56):   P_CLS_stage2   # Mid
Level 3 (56â†’112):  P_CLS_stage1   # Concrete
Level 4 (112â†’224): No CLS         # Detail

# Skip from img_t (56x56)
```

---

## ğŸ› ï¸ Required Changes

### 1. InterleavedTwoStreamViT.forward()

**Location**: Line ~450

**Change**:
```python
# Add at the end of forward()
p_cls_intermediates = {}

for stage in range(self.num_stages):
    # ... process blocks ...

    # Save intermediate CLS
    if stage == 0:
        p_cls_intermediates['stage1'] = p_tokens[:, 0].clone()
    elif stage == 1:
        p_cls_intermediates['stage2'] = p_tokens[:, 0].clone()

p_cls_intermediates['final'] = p_tokens[:, 0].clone()

return m_tokens, p_tokens, p_cls_intermediates  # NEW!
```

### 2. VideoDecoder (Complete Redesign)

**Location**: Line ~578

**New structure**:
- Input: `patches`, `img_t`, `p_cls_intermediates`
- Skip connection from `img_t` (downsampled to 56x56)
- CLS injection via FiLM-like modulation
- 4 upsampling levels with appropriate CLS

**Key methods**:
```python
def inject_cls(self, feature_map, cls_token, proj_layer):
    """FiLM-like CLS injection."""
    cls_proj = proj_layer(cls_token).view(B, C, 1, 1)
    return feature_map + cls_proj
```

### 3. TwoStreamEncoder.forward()

**Location**: Line ~533

**Change**:
```python
# Return intermediate CLS
return cls_fused, patches_fused, p_cls_intermediates
```

### 4. TwoStreamVideoPredictor.forward()

**Location**: Line ~655

**Change**:
```python
cls_emb, patches, p_cls_intermediates = self.encoder(img_t, img_tk)
img_pred = self.decoder(patches, img_t, p_cls_intermediates)
```

---

## ğŸ“š Key Design Rationale

### Q: "ì •ë³´ë¥¼ ë„ˆë¬´ ë§ì´ ì£¼ë©´ ë‹¹ì—°íˆ ì˜ ë˜ëŠ” ê²ƒ ì•„ë‹Œê°€?"

**A**:
1. **Pretraining ëª©ì **: Decoder ì„±ëŠ¥ (X) â†’ Encoder representation í’ˆì§ˆ (O)
2. **Task difficulty**: ë„ˆë¬´ ì–´ë ¤ì›€ (ë¶ˆì•ˆì •) vs ì ì ˆí•¨ (ì•ˆì •) vs ë„ˆë¬´ ì‰¬ì›€ (trivial)
3. **Skip â‰  ì •ë‹µ**: U-Net/ResNetì²˜ëŸ¼ gradient flow ê°œì„ ìš©
4. **ìµœì¢… ê²€ì¦**: LIBERO downstream taskì—ì„œ encoderë§Œ ì‚¬ìš©í–ˆì„ ë•Œ

**Reference**: ë©”ì¸ ë©”ëª¨ Section 10 "Decoder Design: Intermediate CLS Injection"

---

## ğŸ§ª Testing Plan

### Quick Test
```bash
cd /workspace
docker exec simpler-eval python3 -c "
from src.models.two_stream import TwoStreamVideoPredictor
import torch

model = TwoStreamVideoPredictor(encoder_type='interleaved').cuda()
img_t = torch.rand(2, 3, 224, 224).cuda()
img_tk = torch.rand(2, 3, 224, 224).cuda()

img_pred, cls_emb = model(img_t, img_tk)
print(f'âœ“ Forward: {img_pred.shape}')

loss = torch.nn.functional.mse_loss(img_pred, img_tk)
loss.backward()
print('âœ“ Backward OK')
"
```

### Training Test (BridgeV2)
```bash
docker exec simpler-eval python3 src/models/two_stream.py --test train --epochs 1 --batch-size 8
```

---

## ğŸ“‹ Next Steps After Decoder Update

1. **Sanity check**: Lossê°€ ì¤„ì–´ë“œëŠ”ì§€ í™•ì¸
2. **Component ablation**:
   - A: Patchesë§Œ (no skip, no CLS)
   - B: + img_t only
   - C: + img_t + final CLS
   - D: + img_t + intermediate CLS + skip (í˜„ì¬ êµ¬í˜„)
3. **EgoDex pretraining**: Bridge V2 â†’ EgoDexë¡œ ì „í™˜
4. **LIBERO transfer**: Stage 3 ì‹¤í—˜

---

## ğŸ”— Key References

- **Main memo**: `references/ë…¼ë¬¸ - Action-Agnostic Visual Behavior Representation.md`
  - Section 10: Decoder Design Q&A
  - Section "ì‹¤í—˜ ê³„íš": Stage 0-3
  - Section "ì‹¤í—˜ìœ¼ë¡œ ê²€ì¦ ê°€ëŠ¥í•œ ì£¼ì¥": ë¬´ì—‡ì„ ê²€ì¦í•  ìˆ˜ ìˆëŠ”ì§€

- **Concept notes**:
  - `Pixel-wise Channel Fusion for Behavior Representation.md`
  - `Two-Stream Image Preprocessing.md`

---

## âš ï¸ Important Notes

1. **Breaking change**: Old checkpoints incompatible
2. **Dataset**: Currently Bridge V2, should switch to EgoDex
3. **Strategy**: Start simple (baseline) â†’ add components â†’ ablate
4. **Final goal**: LIBERO transfer, not pretraining loss
